{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from hashlib import sha256\n",
    "import threading\n",
    "import sys\n",
    "import socket\n",
    "import time\n",
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class partial_block:\n",
    "    def __init__(self, parenthash, height):\n",
    "        self.parenthash = sha256(pickle.dumps(int(0))).hexdigest()\n",
    "        self.txs = []\n",
    "        self.height = height\n",
    "    def blockhash(self):\n",
    "        return sha256(pickle.dumps(self)).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class block:\n",
    "    def __init__(self, nonce, partial_block):\n",
    "        self.nonce = sha256(pickle.dumps(int(0))).hexdigest()\n",
    "        self.partial_block = partial_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class blockchain:\n",
    "    def __init__(self, genesis_hash):\n",
    "        self.blocks = {} # Block:Parent\n",
    "        self.blockheight = {} # Blockhash: height \n",
    "        self.blocks[genesis_hash] = 0\n",
    "        self.head = genesis_hash # Hash of the head block\n",
    "        self.longest_chain = [genesis_hash] #List of blockhashes on the longest chain\n",
    "        self.len = 1\n",
    "        self.tx_included = {} #TXID: TX at the head\n",
    "        self.blockdb = {} #Blockhash to block\n",
    "        self.state_map = {gensis_hash:{}} #Block hash to state mapping\n",
    "    def insert(self, block):\n",
    "        blockhash = block.partial_block.blockhash()\n",
    "        parenthash = block.partial_block.parenthash\n",
    "        if parenthash not in self.blocks.keys():\n",
    "            return \"orphan_block\"\n",
    "        height = block.partial_block.height\n",
    "        # Update Statemap\n",
    "        temp_state = self.state_map[parenthash].copy()\n",
    "        (temp_state,validity_bool) = stf(temp_state,block.partial_block.txs)\n",
    "        if not validity_bool:\n",
    "            return \"invalid_block\"\n",
    "        self.state_map[blockhash] = temp_state\n",
    "        #Updatestatemap complete\n",
    "        self.blocks[blockhash] = parenthash\n",
    "        self.blockheight[blockhash] = height\n",
    "        self.blockdb[blockhash] = block\n",
    "        if self.head == parenthash: # The normal scenario\n",
    "            self.head = blockhash\n",
    "            self.len = self.len + 1\n",
    "            self.longest_chain.append(blockhash)\n",
    "            #update tx_included\n",
    "            for tx in block.partial_block.txs:\n",
    "                self.tx_included[tx.txid] = tx\n",
    "            #update tx_included complete\n",
    "        elif height > self.len: #CAUTION: Do not do blockchain.insert for orphan blocks\n",
    "            connected_ancestor = parenthash\n",
    "            self.head = blockhash\n",
    "            self.len = height\n",
    "            # Now update the longest chain\n",
    "            new_suffix = [parenthash,blockhash]\n",
    "            while connected_ancestor not in self.longest_chain:\n",
    "                connected_ancestor = self.blocks[connected_ancestor] # Look for previous generation\n",
    "                new_suffix = [connected_ancestor] + new_suffix\n",
    "            ca_height = self.blockheight[connected_ancestor]\n",
    "            removed_suffix = self.longest_chain[(ca_height-1):]\n",
    "            self.longest_chain = self.longest_chain[:(ca_height-1)]\n",
    "            self.longest_chain = self.longest_chain + new_suffix\n",
    "            #update tx_included\n",
    "            for removed_bh in removed_suffix:\n",
    "                removed_blk = self.blockdb[removed_bh]\n",
    "                for tx in removed_blk.partial_block.txs:\n",
    "                    del(self.tx_included[tx.txid])\n",
    "            for added_bh in new_suffix:\n",
    "                added_blk = self.blockdb[added_bh]\n",
    "                for tx in added_blk.partial_block.txs:\n",
    "                    self.tx_included[tx.txid] = tx\n",
    "            #update tx_included complete\n",
    "        else:\n",
    "            pass\n",
    "        return \"block_processed\"\n",
    "    def head_state(self):\n",
    "        return self.state_map[self.head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.partial_block object at 0x1098bb0f0>\n",
      "f8b382a39a28a91a696fc22f03c2cb7a25421035703829db619536117bbec961\n",
      "f8b382a39a28a91a696fc22f03c2cb7a25421035703829db619536117bbec961\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "mining_block = partial_block(sha256(pickle.dumps(int(0))).hexdigest(),2)\n",
    "mining_block.parenthash = sha256(pickle.dumps(int(1))).hexdigest()\n",
    "mining_block.txs.append(\"TX1\")\n",
    "print(mining_block)\n",
    "print(mining_block.blockhash())\n",
    "text = str(mining_block.blockhash())\n",
    "print(text)\n",
    "print(type(str(mining_block.parenthash)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = {} # Latest local state\n",
    "state_map = {} \n",
    "blockdb = {} #Block hash to block    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TX1']\n",
      "4d672a9db795f0105d536626cd190c28ed199cc8d145e2349e5457f7ff6f38be\n",
      "b'\\n'\n",
      "b'BLOCK ccopy_reg\\n_reconstructor\\np0\\n(c__main__\\npartial_block\\np1\\nc__builtin__\\nobject\\np2\\nNtp3\\nRp4\\n(dp5\\nVparenthash\\np6\\nV4d672a9db795f0105d536626cd190c28ed199cc8d145e2349e5457f7ff6f38be\\np7\\nsVtxs\\np8\\n(lp9\\nVTX1\\np10\\nasVheight\\np11\\nL2L\\nsb.'\n",
      "BLOCK ccopy_reg\n",
      "_reconstructor\n",
      "p0\n",
      "(c__main__\n",
      "partial_block\n",
      "p1\n",
      "c__builtin__\n",
      "object\n",
      "p2\n",
      "Ntp3\n",
      "Rp4\n",
      "(dp5\n",
      "Vparenthash\n",
      "p6\n",
      "V4d672a9db795f0105d536626cd190c28ed199cc8d145e2349e5457f7ff6f38be\n",
      "p7\n",
      "sVtxs\n",
      "p8\n",
      "(lp9\n",
      "VTX1\n",
      "p10\n",
      "asVheight\n",
      "p11\n",
      "L2L\n",
      "sb.\n",
      "BLOCK\n",
      "['TX1']\n",
      "4d672a9db795f0105d536626cd190c28ed199cc8d145e2349e5457f7ff6f38be\n"
     ]
    }
   ],
   "source": [
    "# Communication handling\n",
    "print(mining_block.txs)\n",
    "print(mining_block.parenthash)\n",
    "text_block = pickle.dumps(mining_block,0)\n",
    "block_message = f\"BLOCK \"\n",
    "end_line_encode = \"\\n\".encode()\n",
    "print(end_line_encode)\n",
    "\n",
    "encoded_block_message = block_message.encode() + text_block\n",
    "decoded_block_message = encoded_block_message.decode() # Decoded block message looks weird after line_sp[0]\n",
    "print(encoded_block_message)\n",
    "print(decoded_block_message)\n",
    "line_sp = decoded_block_message.split(' ')\n",
    "print(line_sp[0])\n",
    "decoded_mining_block = pickle.loads(decoded_block_message.encode()[6:])\n",
    "print(decoded_mining_block.txs)\n",
    "print(decoded_mining_block.parenthash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{1: 3, 3: 4, 'foo': 'bar'}\n",
      "[2]\n",
      "[2]\n",
      "24c04d87a97bdcefc011d2dd182eba1beaedfe91ae22e632ffb73e5ae7086bed\n"
     ]
    }
   ],
   "source": [
    "#Playground\n",
    "def state_change(d):\n",
    "    internal = d.copy()\n",
    "    internal[\"foo\"] = \"bar\"\n",
    "    return internal\n",
    "a = {1:2,3:4}\n",
    "b = state_change(a)\n",
    "print(2 not in a)\n",
    "b[1]=3\n",
    "print(b)\n",
    "a = [1,2,3]\n",
    "for i in a:\n",
    "    a.remove(i)\n",
    "print(a)\n",
    "print(a)\n",
    "print(sha256(pickle.dumps(int(0))).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class orphan_buffer:\n",
    "    def __init__(self):\n",
    "        self.blocks_to_parent = {} #Blockhash : parent\n",
    "        self.blockdb = {} #Blockhash:Block\n",
    "        self.dependents = {} # Parent: [list of blocks(sons)]\n",
    "    def check_dependency(self, parenthash):\n",
    "        if parenthash in self.dependents.keys():\n",
    "            return self.dependents[parenthash]\n",
    "        else:\n",
    "            return []\n",
    "    def insert(self, block):\n",
    "        blockhash = block.partial_block.blockhash()\n",
    "        parenthash = block.partial_block.parenthash\n",
    "        self.blocks_to_parent[blockhash] = parenthash\n",
    "        self.blockdb[blockhash] = block\n",
    "        if parenthash not in self.dependents:\n",
    "            self.dependents[parenthash] = [blockhash]\n",
    "        else:\n",
    "            self.dependents[parenthash].append(blockhash)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mempool:\n",
    "    def __init__(self):\n",
    "        self.transactions = [] #Need list since we need order\n",
    "    def update_mempool_vanilla(self,block):\n",
    "        block_txs = block.partial_block.txs\n",
    "        self.transctions = [tx for tx in self.transactions if tx not in block_txs] #Remove transactions in block\n",
    "    def update_mempool_state(self,state,tx_included):\n",
    "        new_state = state.copy() #important to do dict copy\n",
    "        self.transctions = [tx for tx in self.transactions if tx not in tx_included] #Remove transactions previously included\n",
    "        for tx in self.transactions:\n",
    "            (new_state, validity_bool) = stf(new_state, [tx])\n",
    "            if not validity_bool:\n",
    "                self.transactions.remove(tx)\n",
    "    def insert(self,tx): # inserts unvalidated transactions, need to run update_mempool_state before assembling block\n",
    "        self.transactions.append(tx)\n",
    "    def get_tx(self,state,tx_included):\n",
    "        self.update_mempool_state(state,tx_included)\n",
    "        extracted_tx = self.transactions[:(min(2000,len(self.transactions)))]\n",
    "        return extracted_tx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stf(state, txs):\n",
    "    temp_state = state.copy()\n",
    "    valid_bool = True\n",
    "    for tx in txs:\n",
    "        if tx.withdraw==0:\n",
    "            if tx.deposit in temp_state.keys():\n",
    "                temp_state[tx.deposit] = temp_state[tx.deposit] + tx.amount\n",
    "            else:\n",
    "                temp_state[tx_deposit] = tx.amount\n",
    "        else:    \n",
    "            if temp_state[tx.withdraw] < tx.amount:\n",
    "                valid_bool = False\n",
    "            else:\n",
    "                temp_state[tx.withdraw] = temp_state[tx.withdraw] - tx.amount\n",
    "                if tx.deposit in temp_state.keys():\n",
    "                    temp_state[tx.deposit] = temp_state[tx.deposit] + tx.amount\n",
    "                else:\n",
    "                    temp_state[tx_deposit] = tx.amount\n",
    "            \n",
    "    return (temp_state, valid_bool)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class transaction:\n",
    "    def __init__(self, txid, withdraw, deposit, amount):\n",
    "        self.txid = txid\n",
    "        self.withdraw = withdraw\n",
    "        self.deposit = deposit\n",
    "        self.amount = amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rcvd_blk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-304e3cd5a398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpartial_blk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mrcvd_bh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcvd_blk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblockhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mrcvd_bh_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrcvd_bh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrcvd_bh\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrcvd_bh\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morphan_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks_to_parent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrcvd_bh\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrcvd_bh_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rcvd_blk' is not defined"
     ]
    }
   ],
   "source": [
    "# Network Worker\n",
    "rcvd_bh_buffer = {}\n",
    "def process_block(rcvd_blk, rcvd_bh):\n",
    "    chain_msg = chain.insert(rcvd_blk)\n",
    "    if chain_msg == \"block_processed\":\n",
    "        dependencies = orphan_buffer.check_dependency(rcvd_bh)\n",
    "        for orp_bh in dependencies:\n",
    "            orp_blk = orphan_buffer.blockdb[orp_bh]\n",
    "            process_block(orp_blk,orp_bh)\n",
    "            del(orphan_buffer.blocks_to_parent[orp_bh])\n",
    "            del(orphan_buffer.blockdb[orp_bh])\n",
    "        del orphan_buffer.dependents[rcvd_bh]\n",
    "    if chain_msg == \"orphan_block\":\n",
    "        orphan_buffer.insert(rcvd_blk)    \n",
    "    return None\n",
    "\n",
    "def form_block():\n",
    "    height = chain.len + 1\n",
    "    parenthash = chain.head\n",
    "    partial_blk = partial_block(parenthash,height)\n",
    "    partial_blk.txs = mempool.get_tx(chain.head_state(), chain.tx_included)\n",
    "    return partial_blk\n",
    "\n",
    "rcvd_bh = rcvd_blk.partial_block.blockhash()\n",
    "rcvd_bh_buffer[rcvd_bh] = None\n",
    "if (rcvd_bh not in chain.blocks) and (rcvd_bh not in orphan_buffer.blocks_to_parent) and (rcvd_bh not in rcvd_bh_buffer):\n",
    "    process_block(rcvd_blk, rcvd_bh)\n",
    "    form_block()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block_serialize(block): # Block + blockhash + nonce + parenthash + height + [txs]\n",
    "    line = \"BLOCK\"\n",
    "    line = line + \" \" + str(block.partial_block.blockhash()) + \" \" + str(block.nonce) \n",
    "    line = line + \" \" + str(block.partial_block.parenthash) + \" \" + str(block.partial_block.height)\n",
    "    for tx in block.partial_block.txs:\n",
    "        line = line + \" \" + str(tx.time) + \" \" + str(tx.txid) + \" \" + str(tx.withdraw)\n",
    "        line = line + \" \" + str(tx.deposit) + \" \" + str(tx.amount)\n",
    "    return line\n",
    "\n",
    "def block_deserialize(line):\n",
    "    split = line.split(\" \")\n",
    "    len_split = len(split)\n",
    "    blockhash = split[1]\n",
    "    nonce = split[2]\n",
    "    parenthash = split[3]\n",
    "    height = int(split[4])\n",
    "    tx_list = []\n",
    "    num_tx = (len_split - 5)/5\n",
    "    for i in range(1,(num_tx+1)):\n",
    "        tx = Transaction(split[5*i+0], split[5*i+1], int(split[5*i+2]), int(split[5*i+3]), int(split[5*i+4]))\n",
    "        tx_list.append(tx)\n",
    "    partial_block = partial_block(parenthash,height)\n",
    "    partial_block.txs = tx_list\n",
    "    block = block(nonce,partial_block)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "def block_deserialize(line): #Pass with BLOCK\n",
    "    split = line.split(\" \")\n",
    "    len_split = len(split)\n",
    "    blockhash = split[1]\n",
    "    nonce = split[2]\n",
    "    parenthash = split[3]\n",
    "    height = int(split[4])\n",
    "    miner_ip = split[5]\n",
    "    miner_port = int(split[6])\n",
    "    tx_list = []\n",
    "    num_tx = int(round((len_split - 7)/5))\n",
    "    for i in range(1,(num_tx+1)):\n",
    "        tx = Transaction(split[2+5*i+0], split[2+5*i+1], int(split[2+5*i+2]), int(split[2+5*i+3]), int(split[2+5*i+4]))\n",
    "        tx_list.append(tx)\n",
    "    partial_blk = partial_block(parenthash,height,miner_ip,miner_port)\n",
    "    partial_blk.txs = tx_list\n",
    "    blk = block(nonce,partial_blk)\n",
    "    return blk\n",
    "\n",
    "def block_serialize(block): # Block + blockhash + nonce + parenthash + height + my_ip + my_port + [txs]\n",
    "    line = \"BLOCK\"\n",
    "    line = line + \" \" + str(block.partial_block.blockhash()) + \" \" + str(block.nonce) \n",
    "    line = line + \" \" + str(block.partial_block.parenthash) + \" \" + str(block.partial_block.height)\n",
    "    line = line + \" \" + str(block.partial_block.miner_id[0]) + \" \" + str(block.partial_block.miner_id[1])\n",
    "    for tx in block.partial_block.txs:\n",
    "        line = line + \" \" + str(tx.time) + \" \" + str(tx.txid) + \" \" + str(tx.withdraw)\n",
    "        line = line + \" \" + str(tx.deposit) + \" \" + str(tx.amount)\n",
    "    return line\n",
    "\n",
    "print(type(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
